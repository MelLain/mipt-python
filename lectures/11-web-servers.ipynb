{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Практикум по программированию на языке Python`\n",
    "<br>\n",
    "\n",
    "## `Занятие 11: Серверная Web-разработка`\n",
    "<br><br>\n",
    "\n",
    "### `Роман Ищенко (roman.ischenko@gmail.com), Мурат Апишев (mel-lain@yandex.ru)`\n",
    "\n",
    "#### `Москва, 2022`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_last_script(use_cached=True):\n",
    "    import os\n",
    "    if not os.path.exists('temp.txt') or not use_cached:\n",
    "        with open('temp.txt', 'w') as fout:\n",
    "            fout.write(In[len(In)-2])\n",
    "    !python temp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Асинхронность`\n",
    "\n",
    "Используется стандартный с версии 3.4 модуль `asyncio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 started at 14:43:57\n",
      "hello\n",
      "world\n",
      "test1 finished at 14:44:00\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "async def test1():\n",
    "    print(f\"test1 started at {time.strftime('%X')}\")\n",
    "\n",
    "    await say_after(1, 'hello')\n",
    "    await say_after(2, 'world')\n",
    "\n",
    "    print(f\"test1 finished at {time.strftime('%X')}\")\n",
    "\n",
    "    \n",
    "await test1()\n",
    "\n",
    "# asyncio.run(test1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2 started at 14:46:09\n",
      "hello\n",
      "world\n",
      "test2 finished at 14:46:13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def test2():\n",
    "    task1 = asyncio.create_task(\n",
    "        say_after(3, 'hello'))\n",
    "\n",
    "    task2 = asyncio.create_task(\n",
    "        say_after(4, 'world'))\n",
    "\n",
    "    print(f\"test2 started at {time.strftime('%X')}\")\n",
    "\n",
    "    await task1\n",
    "    await task2\n",
    "\n",
    "    print(f\"test2 finished at {time.strftime('%X')}\")\n",
    "    \n",
    "await test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 started at 14:48:50\n",
      "test2 started at 14:48:50\n",
      "hello\n",
      "hello\n",
      "world\n",
      "test1 finished at 14:48:53\n",
      "world\n",
      "test2 finished at 14:48:54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res1, res2 = await asyncio.gather(test1(), test2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 started at 14:50:27\n",
      "hello\n",
      "timeout!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    await asyncio.wait_for(test1(), timeout=2.0)\n",
    "except asyncio.TimeoutError:\n",
    "    print('timeout!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Python web-server libs`\n",
    "\n",
    "#### `Flask`\n",
    "Flask — микрофреймворк для создания вебсайтов на языке Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Простейший сервер на flask\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "   return 'Hello, World!'\n",
    "   \n",
    "@app.route('/path')\n",
    "def hello_world():\n",
    "   return 'Hello, Path!'\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Server': 'Werkzeug/2.1.2 Python/3.8.12', 'Date': 'Thu, 12 May 2022 12:04:56 GMT', 'Content-Type': 'application/json', 'Content-Length': '25', 'Connection': 'close'}\n",
      "b'{\"data\":\"Hello, World!\"}\\n'\n"
     ]
    }
   ],
   "source": [
    "# Можно открыть в браузере или написать простейший клиент на Python\n",
    "import requests\n",
    "r = requests.get('http://127.0.0.1:5000/?a=10&b=20')\n",
    "print(r.headers)\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию `route` отвечает только на `GET` запросы.<br>\n",
    "Если нужно, можно явно добавить HTTP-методы, которые будут обрабатываться\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def hello_world():\n",
    "    print(request.method)\n",
    "    return {'data': 'Hello, World!'}\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В пути можно использовать переменные\n",
    "\n",
    "Синтаксис: `<converter:variable_name>`\n",
    "\n",
    "Доступные converters:\n",
    "- string\n",
    "- int\n",
    "- float\n",
    "- path\n",
    "- uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/hello/<string:name>')\n",
    "def hello_name(name):\n",
    "    return f'Hello {name}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, John!'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('http://127.0.0.1:5000/hello/John')\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask используется для разработки и отладки.\n",
    "\n",
    "Для промышленной эксплуатации необходимо использование WSGI (Web Server Gateway Interface) сервера:\n",
    "- WSGI-сервера были разработаны чтобы обрабатывать множество запросов одновременно. А фреймворки (в том числе flask) не предназначены для обработки тысяч запросов и не дают решения того, как наилучшим образом маршрутизировать запросы с веб-сервера.\n",
    "- с WSGI  не нужно беспокоиться о том, как ваша конкретная инфраструктура использует стандарт WSGI.\n",
    "- WSGI дает Вам гибкость в изменении компонентов веб-стека без изменения приложения, которое работает с WSGI.\n",
    "\n",
    "Если не планируется большой нагрузки, для `flask` это может быть `waitress`.\n",
    "\n",
    "Установка: `pipenv install waitress`\n",
    "\n",
    "Использование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waitress import serve\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "   return 'Hello, World!'\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    # Вместо запуска flask запускаем waitress.serve\n",
    "    # app.run(threaded=False, processes=2)\n",
    "    #  serve(app, host='0.0.0.0', port='5000', threads=2, connection_limit=4)\n",
    "    serve(app, host='0.0.0.0', port='5000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Либо запускаем из командной строки: `waitress-serve --port 5000 '<имя модуля>:<перемнная приложения>'`\n",
    "\n",
    "Если наш файл называется `server.py`, то наш пример можно запустить командой: `waitress-serve --port 5000 'server:app'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `FastAPI`\n",
    "\n",
    "FastAPI — фреймворк для создания лаконичных и довольно быстрых HTTP API-серверов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def hello_world(q: Optional[str] = None):\n",
    "    return {'data': f'Hello, World! Param: {q}'}\n",
    "\n",
    "\n",
    "@app.post(\"/items/{item_id}\")\n",
    "@app.get(\"/items/{item_id}\")\n",
    "def read_item(item_id: int, a: int, q: Optional[str] = None):\n",
    "    return {\"item_id\": item_id, \"q\": q}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@app.post(\"/\")\n",
    "async def create_item(item: Item):\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 b'{\"detail\":[{\"loc\":[\"body\",\"name\"],\"msg\":\"field required\",\"type\":\"value_error.missing\"}]}'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.post('http://127.0.0.1:8000/', json={'name1': 'John'})\n",
    "print(r.status_code, r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAPI требует уже ASGI (Asynchronous Standard Gateway Interface) сервера, например, uvicorn\n",
    "\n",
    "Запуск приложения: `uvicorn '<имя модуля>:<перемнная приложения>'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все запросы к веб-сервису выполняются последовательно. Можно использовать асинхронность и многопоточность, но мы знаем, что она сработает не во всех случаях.\n",
    "\n",
    "Эту проблему решают масштабированием через внешние WSGI-серверы. Для Python их существует некоторое количество: Bjoern, uWSGI, mod_wsgi, Meinheld, CherryPy, Gunicorn.\n",
    "\n",
    "Gunicorn — это WSGI-сервер, созданный для использования в UNIX-системах. Название — сокращенная и комбинированная версия слов «Green Unicorn». На самом сайте проекта есть зеленый единорог. Gunicorn был перенесен из проекта «Unicorn» из языка Ruby. Он относительно быстрый, не требует много ресурсов, легко запускается и работает с широким спектром веб-фреймворков.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*nFxyDwJ2DEH1G5PMKPMj1g.png\"/>\n",
    "\n",
    "Запуск для нашего примера для Flask: `gunicorn --bind 0.0.0.0:5000 --workers 4 'server:app'`\n",
    "\n",
    "Запуск для нашего примера для FastAPI:`gunicorn --access-logfile - --bind 0.0.0.0:8000 --workers 2 -k uvicorn.workers.UvicornWorker server:app`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример сервера на Python`\n",
    "\n",
    "- Опишем код учебного серверного приложения для обучения и использования лог-регрессии на текстах<br><br>\n",
    "\n",
    "- Что требуется сделать:\n",
    "    - код классификатора (`classifier.py`)\n",
    "    - код сервера (`server.py`)\n",
    "    - код клиентских запросов\n",
    "    - код `Pipfile`<br><br>\n",
    "\n",
    "- Для упрощения\n",
    "    - опустим ряд проверок корректности\n",
    "    - требования к эффективности реализации кода классификатора\n",
    "    - логгирование<br><br>\n",
    "\n",
    "- Все файлы находятся в одной корневой директории проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `classifier.py`\n",
    "\n",
    "- Импорты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Union, Tuple\n",
    "from dataclasses import dataclass\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Классы-конфигурации методов (удобно использовать `dataclass`-ы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FitConfig:\n",
    "    model_path: str\n",
    "    feature_type: Union[Literal['tf-idf'], Literal['bow']]\n",
    "\n",
    "@dataclass\n",
    "class PredictConfig:\n",
    "    model_path: str\n",
    "    top_n: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `classifier.py`\n",
    "\n",
    "- Класс `TextClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    @staticmethod\n",
    "    def fit(texts: List[str], labels: List[str], config: FitConfig) -> None:\n",
    "        if config.feature_type == 'tf-idf':\n",
    "            vectorizer = TfidfVectorizer()\n",
    "\n",
    "        elif config.feature_type == 'bow':\n",
    "            vectorizer = CountVectorizer()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Unknown config.feature_type: \"{config.feature_type}\"')\n",
    "\n",
    "        data = vectorizer.fit_transform(texts)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(data, labels)\n",
    "\n",
    "        model_path = Path(config.model_path)\n",
    "\n",
    "        if model_path.exists():\n",
    "            shutil.rmtree(model_path)\n",
    "        model_path.mkdir()\n",
    "\n",
    "        with open(model_path / 'model.pkl', 'wb') as fout:\n",
    "            pickle.dump(model, fout)\n",
    "\n",
    "        with open(model_path / 'vectorizer.pkl', 'wb') as fout:\n",
    "            pickle.dump(vectorizer, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `classifier.py`\n",
    "\n",
    "- Класс `TextClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextClassifier:\n",
    "    @staticmethod\n",
    "    def predict(texts: List[str], config: PredictConfig) -> List[List[Tuple[str, float]]]:\n",
    "        model_path = Path(config.model_path)\n",
    "\n",
    "        if not model_path.exists() or not model_path.is_dir():\n",
    "            raise ValueError(f'Path \"{model_path}\" is not a valid path to model')\n",
    "\n",
    "        if not (model_path / 'model.pkl').exists() or not (model_path / 'vectorizer.pkl').exists():\n",
    "            raise ValueError(f'Model from \"{model_path}\" is corrupted')\n",
    "\n",
    "        if config.top_n <= 0:\n",
    "            raise ValueError(f'Top n value \"{config.top_n}\" must be positive int')\n",
    "\n",
    "        with open(model_path / 'model.pkl', 'rb') as fin:\n",
    "            model = pickle.load(fin)\n",
    "\n",
    "        with open(model_path / 'vectorizer.pkl', 'rb') as fin:\n",
    "            vectorizer = pickle.load(fin)\n",
    "\n",
    "        scores_list = model.predict_proba(vectorizer.transform(texts))\n",
    "\n",
    "        predicted = []\n",
    "        for scores in scores_list:\n",
    "            sorted_scores = np.sort(scores)[::-1]\n",
    "            sorted_labels = [model.classes_[i] for i in np.argsort(scores)][::-1]\n",
    "            predicted.append(list(zip(sorted_labels, sorted_scores))[: config.top_n])\n",
    "\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Импорты и объявление переменной приложения `app`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from waitress import serve\n",
    "\n",
    "from classifier import TextClassifier, FitConfig, PredictConfig\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Добавим в приложение обработчик `POST`-запроса на обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/fit', methods=['POST'])\n",
    "def fit():\n",
    "    try:\n",
    "        texts = request.json['texts']\n",
    "        labels = request.json['labels']\n",
    "\n",
    "        config_dict = request.json['config']\n",
    "        config = FitConfig(model_path=config_dict['model_path'], feature_type=config_dict['feature_type'])\n",
    "\n",
    "        TextClassifier.fit(texts=texts, labels=labels, config=config)\n",
    "\n",
    "        return {'success': True}\n",
    "\n",
    "    except Exception as error:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'message': str(error),\n",
    "            'traceback': traceback.format_exc(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Добавим в приложение обработчик `POST`-запроса на применение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        texts = request.json['texts']\n",
    "        config_dict = request.json['config']\n",
    "        config = PredictConfig(model_path=config_dict['model_path'], top_n=config_dict['top_n'])\n",
    "\n",
    "        predicted = TextClassifier.predict(texts=texts, config=config)\n",
    "\n",
    "        return {\n",
    "            'success': True,\n",
    "            'predicted': predicted,\n",
    "        }\n",
    "    except Exception as error:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'message': str(error),\n",
    "            'traceback': traceback.format_exc(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Определим код запуска хостинга сервера средствами `flask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 3:\n",
    "        print('Run `python server.py <HOST> <PORT>`')\n",
    "        sys.exit(1)\n",
    "\n",
    "    host = sys.argv[1]\n",
    "    port = sys.argv[2]\n",
    "\n",
    "    print(f'Start server on {host}:{port}')\n",
    "    app.run(host=host, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Поднять сервер можно командой\n",
    "\n",
    "    `python server.py 0.0.0.0 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "- Пример запроса на обучение модели для библиотеки `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "model_path = 'test-model'\n",
    "\n",
    "result_fit = requests.post(url='http://0.0.0.0:1234/fit',\n",
    "                           json={\n",
    "                               'texts': ['i love cats', 'cats are the best', 'what about dogs', 'i love dogs'],\n",
    "                               'labels': ['cats', 'cats', 'dogs', 'dogs'],\n",
    "                               'config': {'model_path': model_path, 'feature_type': 'bow'},\n",
    "                               })\n",
    "print(result_fit.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x 2 mel-lain mel-lain  4096 апр 21 19:01 test-model\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ~/flask-server-example | grep test-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "- Пример запроса на предсказание модели для библиотеки `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted': [[['dogs', 0.6556448019571932], ['cats', 0.3443551980428068]], [['cats', 0.6317903516164188], ['dogs', 0.36820964838358117]]], 'success': True}\n"
     ]
    }
   ],
   "source": [
    "result_predict = requests.post(url='http://0.0.0.0:1234/predict',\n",
    "                               json={\n",
    "                                   'texts': ['i like dogs', 'i walk with cats'],\n",
    "                                   'config': {'model_path': model_path, 'top_n': 2},\n",
    "                               })\n",
    "print(result_predict.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask, нагрузочное тестирование`\n",
    "\n",
    "\n",
    "- Для оценки скорости обработки используем стандартный текстовый датасет для классификации из `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "model_path = 'test-model'\n",
    "\n",
    "dataset = fetch_20newsgroups()\n",
    "texts = dataset['data']\n",
    "labels = [dataset['target_names'][i] for i in dataset['target']]\n",
    "\n",
    "result_fit = requests.post(url='http://0.0.0.0:1234/fit',\n",
    "                           json={\n",
    "                               'texts': texts,\n",
    "                               'labels': labels,\n",
    "                               'config': {'model_path': model_path, 'feature_type': 'bow'},\n",
    "                               })\n",
    "print(result_fit.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask, нагрузочное тестирование`\n",
    "\n",
    "- Для запуска асинхронных запросов используем библиотеку `aiohttp`\n",
    "- Библиотека не позволяет работу из Jupyter Notebook (из-за наличия event loop), нужно запустить код ниже в виде скрипта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "num_requests = 20\n",
    "model_path = 'test-model'\n",
    "dataset = fetch_20newsgroups()\n",
    "texts = dataset['data']\n",
    "labels = [dataset['target_names'][i] for i in dataset['target']]\n",
    "\n",
    "async def post(session):\n",
    "    async with session.post(url='http://0.0.0.0:1234/predict',\n",
    "                            json={\n",
    "                                'texts': texts[: 5000],\n",
    "                                'config': {'model_path': model_path, 'top_n': 3}\n",
    "                            }) as response:\n",
    "        await response.read()\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await asyncio.gather(*[post(session) for _ in range(num_requests)])\n",
    "\n",
    "try:\n",
    "    ts = time.time()\n",
    "    asyncio.run(main())\n",
    "    print(f'Elapsed time for {num_requests} requests: {round(time.time() - ts, 2)} sec.')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 20 requests: 36.55 sec.\r\n"
     ]
    }
   ],
   "source": [
    "run_last_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask, нагрузочное тестирование`\n",
    "\n",
    "- Встроенный сервер Flask является тестовым и не предназначен для использования в production-окружении (мнение разработчиков Flask)\n",
    "- По этой причине лучше \"закрыть\" его WSGI-сервером, например, `waitress`\n",
    "- Это даст ускорение, в т.ч. за счёт того, что сервер и обработчик запросов будут работать в разных процессах (на многоядерных системах)<br><br>\n",
    "\n",
    "- Изменим код запуска хостинга сервера средствами `flask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from waitress import serve\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 3:\n",
    "        print('Run `python server.py <HOST> <PORT>`')\n",
    "        sys.exit(1)\n",
    "\n",
    "    host = sys.argv[1]\n",
    "    port = sys.argv[2]\n",
    "\n",
    "    print(f'Start server on {host}:{port}')\n",
    "    serve(app, host=host, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Перезапустим сервер и прогоним тест вторично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 20 requests: 21.29 sec.\r\n"
     ]
    }
   ],
   "source": [
    "run_last_script(use_cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask, нагрузочное тестирование`\n",
    "\n",
    "- При наличии ресурсов обработку запросов можно производить параллельно\n",
    "- Запуск нескольких параллельных процессов-обработчиков и балансировку запросов можно обеспечить с помощью `gunicorn`\n",
    "- Для этого достаточно запустить сервер командой\n",
    "\n",
    "    `gunicorn --bind 0.0.0.0:1234 --workers 2 'server:app'`<br><br>\n",
    "    \n",
    "- Прогоним тест ещё раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 20 requests: 10.65 sec.\r\n"
     ]
    }
   ],
   "source": [
    "run_last_script(use_cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: Flask`\n",
    "\n",
    "Файл `Pipfile`\n",
    "\n",
    "```\n",
    "[[source]]\n",
    "name = \"pypi\"\n",
    "url = \"https://pypi.org/simple\"\n",
    "verify_ssl = true\n",
    "\n",
    "[packages]\n",
    "flask = \"*\"\n",
    "waitress = \"*\"\n",
    "scikit-learn = \"*\"\n",
    "gunicorn = \"*\"\n",
    "aiohttp = \"*\"\n",
    "\n",
    "[requires]\n",
    "python_version = \"3.8\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Библиотека FastAPI`\n",
    "\n",
    "- Flask основан на интерфейсе WSGI, FastAPI - на более быстром и современном ASGI (а именно на фреймворке Starlette)\n",
    "- Flask работает на уровне JSON и требует ручной валидации данных, FastAPI использует Pydantic\n",
    "- Flask требует документирования API, FastAPI поддерживает OpenAPI и позволяет выводить API-спеки автоматически\n",
    "- Скорость и удобство разработки у обоих фреймворков схожая\n",
    "- FastAPI + Uvicorn + Gunicorn позволяет описывать и хостить production-серверы на Python на уровне Go и NodeJS<br><br>\n",
    "\n",
    "- Реализуем описанный выше пример на FastAPI\n",
    "- Опишем детальный набор структур данных в файле `structures.py` (его можно оптимизировать для одного сервиса, а можно развить в систему типов, если похожих сервисов будет много)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `Pipfile`\n",
    "\n",
    "```\n",
    "[[source]]\n",
    "name = \"pypi\"\n",
    "url = \"https://pypi.org/simple\"\n",
    "verify_ssl = true\n",
    "\n",
    "[packages]\n",
    "fastapi = \"*\"\n",
    "pydantic = \"*\"\n",
    "scikit-learn = \"*\"\n",
    "gunicorn = \"*\"\n",
    "uvicorn = \"*\"\n",
    "aiohttp = \"*\"\n",
    "\n",
    "[requires]\n",
    "python_version = \"3.8\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `structures.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal, Union, Tuple, Optional\n",
    "from pydantic import BaseModel, constr, PositiveInt, validator\n",
    "\n",
    "class FitConfig(BaseModel):\n",
    "    model_path: constr(min_length=1)\n",
    "    feature_type: Union[Literal['tf-idf'], Literal['bow']]\n",
    "\n",
    "class PredictConfig(BaseModel):\n",
    "    model_path: constr(min_length=1)\n",
    "    top_n: PositiveInt\n",
    "\n",
    "class Texts(BaseModel):\n",
    "    texts: List[str]\n",
    "\n",
    "class Labels(BaseModel):\n",
    "    labels: List[str]\n",
    "\n",
    "class Scores(BaseModel):\n",
    "    scores: List[float]\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    labels_list: List[Labels]\n",
    "    scores_list: List[Scores]\n",
    "\n",
    "class ReturnValue(BaseModel):\n",
    "    success: bool\n",
    "    message: Optional[str]\n",
    "    traceback: Optional[str]\n",
    "\n",
    "class PredictReturnValue(ReturnValue):\n",
    "    prediction: Optional[Prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `classifier.py`\n",
    "\n",
    "- Импорты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from structures import FitConfig, PredictConfig, Texts, Labels, Scores, Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `classifier.py`\n",
    "\n",
    "- Класс `TextClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    @staticmethod\n",
    "    def fit(texts: Texts, labels: Labels, config: FitConfig) -> None:\n",
    "        if config.feature_type == 'tf-idf':\n",
    "            vectorizer = TfidfVectorizer()\n",
    "\n",
    "        elif config.feature_type == 'bow':\n",
    "            vectorizer = CountVectorizer()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Unknown config.feature_type: \"{config.feature_type}\"')\n",
    "\n",
    "        data = vectorizer.fit_transform(texts.values)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(data, labels.values)\n",
    "\n",
    "        ...\n",
    "        # the same as earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `classifier.py`\n",
    "\n",
    "- Класс `TextClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextClassifier:\n",
    "    @staticmethod\n",
    "    def predict(texts: Texts, config: PredictConfig) -> Prediction:\n",
    "        ...\n",
    "        # the same as earlier\n",
    "\n",
    "        scores_list = model.predict_proba(vectorizer.transform(texts.values))\n",
    "\n",
    "        labels_list_ = []\n",
    "        scores_list_ = []\n",
    "\n",
    "        for scores in scores_list:\n",
    "            sorted_scores = list(np.sort(scores))[::-1]\n",
    "            sorted_labels = [model.classes_[i] for i in np.argsort(scores)][::-1]\n",
    "            labels_list_.append(sorted_labels[: config.top_n])\n",
    "            scores_list_.append(sorted_scores[: config.top_n])\n",
    "\n",
    "        return Prediction(\n",
    "            labels_list=[Labels(values=labels) for labels in labels_list_],\n",
    "            scores_list=[Scores(values=scores) for scores in scores_list_],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Импорты и объявление переменной приложения `app` + функция для формирования из метода словаря аргументов с типами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "import traceback\n",
    "\n",
    "import uvicorn\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import create_model\n",
    "\n",
    "from classifier import TextClassifier\n",
    "from structures import FitConfig, PredictConfig, Texts, ReturnValue, PredictReturnValue\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def get_params(method):\n",
    "    return {k: (v.annotation, ...) for k, v in inspect.signature(method).parameters.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Добавим в приложение обработчик `POST`-запроса на обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/fit\", response_model=ReturnValue, name='Fit')\n",
    "async def fit(request: create_model('FitInput', **get_params(TextClassifier.fit))):\n",
    "    try:\n",
    "        TextClassifier.fit(texts=request.texts, labels=request.labels, config=request.config)\n",
    "\n",
    "        return ReturnValue(success=True)\n",
    "\n",
    "    except Exception as error:\n",
    "        return ReturnValue(\n",
    "            success=False,\n",
    "            message=str(error),\n",
    "            traceback=str(traceback.format_exc()),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Добавим в приложение обработчик `POST`-запроса на применение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict\", response_model=PredictReturnValue, name='Predict')\n",
    "async def predict(request: create_model('PredictInput', **get_params(TextClassifier.predict))):\n",
    "    try:\n",
    "        return PredictReturnValue(success=True,\n",
    "                                  predicted=TextClassifier.predict(texts=request.texts, config=request.config))\n",
    "    except Exception as error:\n",
    "        return PredictReturnValue(\n",
    "            success=False,\n",
    "            message=str(error),\n",
    "            traceback=str(traceback.format_exc()),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "Файл `server.py`\n",
    "\n",
    "- Определим код запуска хостинга сервера средствами `uvicorn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 3:\n",
    "        print('Run `python server.py <HOST> <PORT>`')\n",
    "        sys.exit(1)\n",
    "\n",
    "    host = sys.argv[1]\n",
    "    port = int(sys.argv[2])\n",
    "\n",
    "    uvicorn.run('server:app', host=host, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Поднять сервер можно той же командой\n",
    "\n",
    "    `python server.py 0.0.0.0 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "- API сервиса является самодокументированным за счёт типизации Pydanctic\n",
    "- Посмотреть и опробовать его можно по адресу `<host>:<port>/docs` (Swagger)<br><br>\n",
    "\n",
    "- Пример запроса на обучение модели для библиотеки `requests` (то же самое можно сделать через интерфейс Swagger):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(url='http://0.0.0.0:1234/fit',\n",
    "              json={\n",
    "                  'texts': {\n",
    "                      'values': ['i love cats', 'cats are the best',\n",
    "                                 'what about dogs', 'i love dogs'],\n",
    "                  },\n",
    "                  'labels': {\n",
    "                      'values': ['cats', 'cats', 'dogs', 'dogs'],\n",
    "                  },\n",
    "                  'config': {\n",
    "                      'model_path': model_path,\n",
    "                      'feature_type': 'bow',\n",
    "                  },\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI`\n",
    "\n",
    "- Пример запроса на предсказание модели для библиотеки `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(url='http://0.0.0.0:1234/fit',\n",
    "              json={\n",
    "                  'texts': {\n",
    "                      'values': ['i like dogs', 'i walk with cats'],\n",
    "                  },\n",
    "                  'config': {\n",
    "                      'model_path': model_path,\n",
    "                      'top_n': 2,\n",
    "                  },\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI, нагрузочное тестирование`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'message': None, 'traceback': None}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "model_path = 'test-model'\n",
    "\n",
    "dataset = fetch_20newsgroups()\n",
    "texts = dataset['data']\n",
    "labels = [dataset['target_names'][i] for i in dataset['target']]\n",
    "\n",
    "result_fit = requests.post(url='http://0.0.0.0:1234/fit',\n",
    "                           json={\n",
    "                               'texts': {'values': texts},\n",
    "                               'labels': {'values': labels},\n",
    "                               'config': {'model_path': model_path, 'feature_type': 'bow'},\n",
    "                               })\n",
    "print(result_fit.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI, нагрузочное тестирование`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "num_requests = 20\n",
    "model_path = 'test-model'\n",
    "\n",
    "async def post(session):\n",
    "    async with session.post(url='http://0.0.0.0:1234/predict',\n",
    "                            json={\n",
    "                                'texts': {'values': texts[: 5000]},\n",
    "                                'config': {'model_path': model_path, 'top_n': 3}\n",
    "                            }) as response:\n",
    "        await response.read()\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await asyncio.gather(*[post(session) for _ in range(num_requests)])\n",
    "\n",
    "dataset = fetch_20newsgroups()\n",
    "texts = dataset['data']\n",
    "labels = [dataset['target_names'][i] for i in dataset['target']]\n",
    "\n",
    "try:\n",
    "    ts = time.time()\n",
    "    asyncio.run(main())\n",
    "    print(f'Elapsed time for {num_requests} requests: {round(time.time() - ts, 2)} sec.')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 20 requests: 21.26 sec.\r\n"
     ]
    }
   ],
   "source": [
    "run_last_script(use_cached=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Пример: FastAPI, нагрузочное тестирование`\n",
    "\n",
    "- Запуск нескольких параллельных процессов-обработчиков и балансировку запросов можно обеспечить с помощью `gunicorn`\n",
    "- Для этого достаточно запустить сервер командой\n",
    "\n",
    "    `gunicorn --bind 0.0.0.0:1234 -w 2 -k uvicorn.workers.UvicornWorker server:app`<br><br>\n",
    "    \n",
    "- Прогоним тест ещё раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 20 requests: 11.21 sec.\r\n"
     ]
    }
   ],
   "source": [
    "run_last_script(use_cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Пример: FastAPI, спецификация API`\n",
    "\n",
    "- Для приложения FastAPI легко получить OpenAPI-спецификацию в виде JSON или YAML\n",
    "- Это спеку можно конвертировать и использовать для формирования запросов на любом подходящем языке программирования\n",
    "\n",
    "Получить спеку приложения в виде JSON можно вызовом `app.openapi()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.openapi().keys()\n",
    "dict_keys(['openapi', 'info', 'paths', 'components'])\n",
    "\n",
    "# app.openapi()['paths']['/fit']\n",
    "{\n",
    "    'post': {\n",
    "        'summary': 'Fit',\n",
    "        'operationId': 'Fit_fit_post',\n",
    "        'requestBody': {\n",
    "            'content': {\n",
    "                'application/json': {\n",
    "                    'schema': {\n",
    "                        '$ref': '#/components/schemas/FitInput'\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'required': True\n",
    "        },\n",
    "        'responses': {\n",
    "            '200': {\n",
    "                'description': 'Successful Response',\n",
    "                'content': {\n",
    "                    'application/json': {\n",
    "                        'schema': {\n",
    "                            '$ref': '#/components/schemas/ReturnValue'\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            '422': {\n",
    "                'description': 'Validation Error',\n",
    "                'content': {\n",
    "                    'application/json': {\n",
    "                        'schema': {\n",
    "                            '$ref': '#/components/schemas/HTTPValidationError'\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Пример: FastAPI, спецификация API`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.openapi()['components']['schemas'].keys()\n",
    "\n",
    "dict_keys(['FitConfig', 'FitInput', 'HTTPValidationError', 'Labels',\n",
    "           'PredictConfig', 'PredictInput', 'PredictReturnValue',\n",
    "           'Prediction', 'ReturnValue', 'Scores', 'Texts', 'ValidationError'])\n",
    "\n",
    "# app.openapi()['components']['schemas']['FitInput']\n",
    "{\n",
    "    'title': 'FitInput',\n",
    "    'required': [\n",
    "        'texts',\n",
    "        'labels',\n",
    "        'config'\n",
    "    ],\n",
    "    'type': 'object',\n",
    "    'properties': {\n",
    "        'texts': {\n",
    "            '$ref': '#/components/schemas/Texts'\n",
    "        },\n",
    "        'labels': {\n",
    "            '$ref': '#/components/schemas/Labels'\n",
    "        },\n",
    "        'config': {\n",
    "            '$ref': '#/components/schemas/FitConfig'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Спасибо за внимание!`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "654ac8a58a760a97f65542d0ae1be60444a9fa4569979b0f4ebe92c522c95f47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
